a
a<-a[a<200]
a
sum(a)
names(a)
head(clean)
source('~/quickfix.R', echo=TRUE)
london<-clean[grep("LONDON",clean$V6),]
london<-london[1:50,]
london$url<-paste("open http://www.github.com/",london$V2,sep="")
london<-london[,c("url")]
write.csv(london,"london_manualcheck.txt",row.names=FALSE,quote=FALSE)
clean<-read.csv("/Users/francinebennett/Downloads/users_clean (1).csv",sep="\t",strip.white=TRUE)
clean<-clean[!duplicated(clean),]
head(clean)
clean<-read.csv("/Users/francinebennett/Downloads/users_clean (1).csv",sep="\t",strip.white=TRUE)
clean<-clean[!duplicated(clean),]
c<-read.csv("/Users/francinebennett/Documents/problems_nesta.txt",header=FALSE)
clean<-subset(clean,!V2 %in% c$V1)
table(clean$V6)
a<-table(clean$V6)
b<-table(clean_again$V6)
clean<-read.csv("/Users/francinebennett/Downloads/users_clean (1).csv",sep="\t",strip.white=TRUE)
clean<-clean[!duplicated(clean),]
c<-read.csv("/Users/francinebennett/Documents/problems_nesta.txt",header=FALSE)
clean_again<-subset(clean,!V2 %in% c$V1)
a<-table(clean$V6)
b<-table(clean_again$V6)
head(a)
a<-a[a>15 & a<1500]
a
b<-b[b>15 & b<1500]
b
head(clean_again)
clean_again[grep("RED HAT",clean_again$V7),]
clean<-read.csv("/Users/francinebennett/Downloads/users_clean (1).csv",sep="\t",strip.white=TRUE)
clean<-clean[!duplicated(clean),]
c<-read.csv("/Users/francinebennett/Documents/problems_nesta.txt",header=FALSE)
clean_again<-subset(clean,!V2 %in% c$V1)
write.csv(clean_again,"users_clean.csv",row.names=FALSE,quote=FALSE,sep="\t")
?write.csv
write.csv(clean_again,"/Users/francinebennett/Dropbox/users_clean.csv",row.names=FALSE,quote=FALSE,sep="\t")
require(RColorBrewer)
?RColorBrewer
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
language_heatmap
language_heatmap <- heatmap(language_matrix, Rowv=NA, Colv=NA, col = brewer.pal(9,"Blues"), scale="row", margins=c(5,10))
a<-read.csv("/Users/francinebennett/Desktop/client/tech.csv",header=FALSE)
a$V2<-as.character(a$V2)
languages<-aggregate(a$V3,by=list(a$V2),FUN=sum)
temp<-subset(languages,x<3000)
head(temp)
temp
a[a$V2 %in% unique(temp$Group.1),]$V2<-"Other"
a<-aggregate(a$V3,by=list(a$V1,a$V2),FUN=sum)
a
unique(a$Group.2)
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
language_heatmap
language_heatmap <- heatmap(language_matrix, Rowv=NA, Colv=NA, col = brewer.pal(9,"Blues"), scale="row", margins=c(5,10))
require(RColorBrewer)
a<-read.csv("/Users/francinebennett/Desktop/client/tech.csv",header=FALSE)
a$V2<-as.character(a$V2)
languages<-aggregate(a$V3,by=list(a$V2),FUN=sum)
temp<-subset(languages,x<5000)
a[a$V2 %in% unique(temp$Group.1),]$V2<-"Other"
a<-aggregate(a$V3,by=list(a$V1,a$V2),FUN=sum)
towns<-aggregate(a$x,by=list(a$Group.1),FUN=sum)
temp<-subset(towns,x>1000)
a<-subset(a,Group.1 %in% temp$Group.1 )
b<-cast(a,Group.1~Group.2,value="x")
row.names(b)<-b$Group.1
b<-b[,2:ncol(b)]
b[is.na(b)]<-0
b<-b[order(rowSums(b),decreasing=FALSE),]
b<-b[,order(colSums(b),decreasing=TRUE)]
language_matrix<- data.matrix(b)
language_matrix[is.na(language_matrix)]<-0
language_heatmap <- heatmap(language_matrix, Rowv=NA, Colv=NA, col = brewer.pal(9,"Blues"), scale="row", margins=c(5,10))
require(RColorBrewer)
a<-read.csv("/Users/francinebennett/Desktop/client/tech.csv",header=FALSE)
a$V2<-as.character(a$V2)
languages<-aggregate(a$V3,by=list(a$V2),FUN=sum)
temp<-subset(languages,x<6000)
a[a$V2 %in% unique(temp$Group.1),]$V2<-"Other"
a<-aggregate(a$V3,by=list(a$V1,a$V2),FUN=sum)
towns<-aggregate(a$x,by=list(a$Group.1),FUN=sum)
temp<-subset(towns,x>1000)
a<-subset(a,Group.1 %in% temp$Group.1 )
b<-cast(a,Group.1~Group.2,value="x")
row.names(b)<-b$Group.1
b<-b[,2:ncol(b)]
b[is.na(b)]<-0
b<-b[order(rowSums(b),decreasing=FALSE),]
b<-b[,order(colSums(b),decreasing=TRUE)]
language_matrix<- data.matrix(b)
language_matrix[is.na(language_matrix)]<-0
language_heatmap <- heatmap(language_matrix, Rowv=NA, Colv=NA, col = brewer.pal(9,"Blues"), scale="row", margins=c(5,10))
temp<-subset(towns,x>2000)
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
language_heatmap <- heatmap(language_matrix, Rowv=NA, Colv=NA, col = brewer.pal(9,"Blues"), scale="row", margins=c(5,10))
language_matrix
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
language_heatmap <- heatmap(language_matrix, Rowv=NA, Colv=NA, col = brewer.pal(9,"Blues"), scale="row", margins=c(5,10))
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
head(b)
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
head(a)
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
subset(a,Group.1=="Sheffield")
subset(a,Group.1=="SHEFFIELD")
subset(a,Group.1=="BIRMINGHAM")
subset(a,Group.1=="cAMBRIDGE")
subset(a,Group.1=="CAMBRIDGE")
subset(a,Group.1=="OXFORD")
head(clean)
source('~/quickfix.R', echo=TRUE)
source('~/quickfix.R', echo=TRUE)
source('~/quickfix.R', echo=TRUE)
head(clean_again)
clean_again[grep("BOX",clean_again$V7),]
clean_again[grep("BOX UK",clean_again$V7),]
clean_again[grep("PIVOTAL",clean_again$V7),]
clean[grep("PIVOTAL",clean$V7),]
clean[grep("FACEBOOK",clean$V7),]
clean[grep("rumble labs",clean$V7),]
clean[grep("RUMBLE",clean$V7),]
clean[grep("HAILO",clean$V7),]
source('~/Desktop/client/stentor/nesta_quickheatmap.R', echo=TRUE)
source('~/quickfix.R', echo=TRUE)
head(clean_again)
clean_again[grep("BOX",clean_again$V7),]
clean_again[grep("BOX UK",clean_again$V7),]
source('~/quickfix.R', echo=TRUE)
head(clean_again)
a<-read.csv("/Users/francinebennett/Downloads/credit_firm_constituencies.txt")
head(a)
a<-read.csv("/Users/francinebennett/Downloads/credit_firm_constituencies.txt",sep="\t")
head(a)
b<-a[grep("Herefordshire",a$constituency.name)]
b<-a[grep("Herefordshire",a$constituency.name),]
head(b)
nrow(b)
b[100,]
head(a)
b[50,]
b[25,]
a<-read.csv("/Users/francinebennett/Downloads/credit_firm_completed.csv.enc")
head(a)
a<-read.csv("/Users/francinebennett/Downloads/credit_firm_completed.csv")
head(a)
b<-a[grep("Herefordshire",a$constituency.name),]
head(b)
nrow(b)
b[100,]
users<-rbind(a,b)
source('~/quickfix.R', echo=TRUE)
head(clean_again)
clean_again[grep("GLOUCESTER",clean_again$V6),]
clean_again[grep("BRISTOL",clean_again$V6),]
clean_again[grep("BRISTOL",clean_again$V6),]
b<-clean_again[grep("BRISTOL",clean_again$V6),]
head(b)
table(b$V7)
b$V7<-as.character(b$V7)
table(b$V7)
b<-clean_again[grep("SWINDON",clean_again$V6),]
b
b<-clean_again[grep("OXFORD",clean_again$V6),]
b
b<-clean_again[grep("BIRMINGHAM",clean_again$V6),]
b
b<-clean_again[grep("BIRMINGHAM|CHELTENHAM|GLOUCESTER|BRISTOL|SWINDON|OXFORD",clean_again$V6),]
nrow(b)
b$V7<-as.character(b$V7)
table(b$V7)
write.csv(table(b$V7),"west_innovators.txt")
b<-clean_again[grep("BIRMINGHAM|CHELTENHAM|GLOUCESTER|BRISTOL|SWINDON|OXFORD|CARDIFF",clean_again$V6),]
b$V7<-as.character(b$V7)
write.csv(table(b$V7),"west_innovators.txt",row.names=FALSE)
write.csv(table(b$V7),"west_innovators.txt",row.names=FALSE,quote=FALSE)
a<-read.csv("/Users/francinebennett/Downloads/credit_firm_completed.csv")
head(a)
summary(a)
nrow(a)
source('~/fca_fix.R', echo=TRUE)
head(notcoded)
summary(notcoded)
source('~/fca_fix.R', echo=TRUE)
head(notcoded)
notcoded_notbelfast<-notcoded[!grep("BT",notcoded$Postcode),]
head(notcoded_notbelfast)
notcoded_notbelfast<-notcoded[grep("BT",notcoded$Postcode),]
head(notcoded_notbelfast)
head(notcoded_notbelfast)
head(notcoded)
notcoded_notbelfast<-notcoded[-grep("BT",notcoded$Postcode),]
head(notcoded_notbelfast)
nrow(notcoded_notbelfast)
nrow(notcoded)
?substr
notcoded_notbelfast$outcode<-substr(notcoded_notbelfast$Postcode,start=1,stop=find(" "))
?find
find(" ","hello world")
?strsplit
notcoded_notbelfast$outcode<-strsplit(notcoded_notbelfast$Postcode," ")[1]
head(notcoded_notbelfast)
notcoded_notbelfast$outcode<-strsplit(notcoded_notbelfast$Postcode," ")[1][1]
head(notcoded_notbelfast)
strsplit(notcoded_notbelfast$Postcode," ")
unlist(strsplit(notcoded_notbelfast$Postcode," "))
unlist(strsplit(notcoded_notbelfast$Postcode," "))[1]
notcoded_notbelfast$outcode<-unlist(strsplit(notcoded_notbelfast$Postcode," "))
notcoded_notbelfast$outcode<-unlist(strsplit(notcoded_notbelfast$Postcode," "))[1]
head(notcoded_notbelfast)
a<-strsplit(notcoded_notbelfast$Postcode," ")
head(a)
lapply(a,unlist)
lapply(a,[1])
lapply(a)
grep(" ","N1 4SD")
gsub(".*\\#(.*)\\..*", "\\1", c("HelloWorld#you.txt"))
gsub(" .*","","N1 4SD")
source('~/fca_fix.R', echo=TRUE)
head(notcoded_notbelfast)
table(notcoded_notbelfast$outcode)
problem_outcode<-table(notcoded_notbelfast$outcode)
source('~/fca_fix.R', echo=TRUE)
problem_outcode
source('~/fca_fix.R', echo=TRUE)
problem_outcode
source('~/fca_fix.R', echo=TRUE)
problem_outcode
as.data.frame(problem_outcode)
source('~/fca_fix.R', echo=TRUE)
?len
?length
source('~/fca_fix.R', echo=TRUE)
head(problem_outcode)
source('~/fca_fix.R', echo=TRUE)
problem_outcode
source('~/fca_fix.R', echo=TRUE)
problem_outcode_long
source('~/fca_fix.R', echo=TRUE)
head(a)
c<-a[grep("City of London",a$constituency.name),]
nrow(c)
c<-a[grep("London",a$constituency.name),]
nrow(c)
head(c)
c<-a[grep("London and Westminster",a$constituency.name),]
head(c)
nrow(c)
c
head(c)
length(unique(c$Licence))
nrow(c)
c$latlong<-paste(c$lat,c$lon)
length(unique(c$latlong))
head(c)
head(c)
table(c$latlong)
r<-table(c$latlong)
r<-r[r>2]
r
r
dim(r)
as.data.frame(r)
subset(c,latlong=="51.5039888750857 -0.149766008621518")
as.data.frame(r)
r<-r[r>10]
r
as.data.frame(r)
subset(c,latlong=="51.5039888750857 -0.149766008621518")
as.data.frame(r)
subset(c,latlong=="51.5039888750857 -0.149766008621518")[,1:5]
subset(c,latlong=="51.5039888750857 -0.149766008621518")[,1:3]
subset(c,latlong=="51.5039888750857 -0.149766008621518")[,2:3]
as.data.frame(r)
subset(c,latlong=="51.5045519984016 -0.147841174225713")[,2:3]
as.data.frame(r)
subset(c,latlong=="51.5165567950281 -0.088418965839804")[,2:3]
nrow(a)
subset(c,latlong=="51.5165567950281 -0.088418965839804")
ni<-read.csv("/Users/francinebennett/Downloads/ni_geocoded.csv")
ni<-read.csv("/Users/francinebennett/Downloads/ni_geocoded.csv")
ni_not<-read.csv("/Users/francinebennett/Downloads/ni_not_geocoded.csv")
head(ni)
head(ni_not)
ni_not
head(ni)
ni$latlong<-paste(ni$lat,ni$lng)
head(ni)
table(ni$latlong)
locations<-table(ni$latlong)
head(locations)
locations<-locations[locations>2]
locations
locations<-locations[locations>6]
locations
names(locations)
concentrated<-subset(ni,latlong %in% names(locations))
concentrated
concentrated<-concentrated[order(concentrated$Name),]
concentrated
subset(ni,Licence==31486)
ni<-read.csv("/Users/francinebennett/Downloads/northern_ireland.csv")
head9ni
head(ni)
ni$latlong<-paste(ni$lat,ni$lng)
locations<-table(ni$latlong)
locations<-locations[locations>6]
locations
concentrated<-subset(ni,latlong %in% names(locations))
concentrated<-concentrated[order(concentrated$Name),]
concentrated
ni<-read.csv("/Users/francinebennett/Downloads/northern_ireland.csv")
#ni_not<-read.csv("/Users/francinebennett/Downloads/ni_not_geocoded.csv")
ni$latlong<-paste(ni$lat,ni$lng)
locations<-table(ni$latlong)
locations<-locations[locations>1]
concentrated<-subset(ni,latlong %in% names(locations))
concentrated<-concentrated[order(concentrated$Name),]
concentrated
locations
subset(ni,latlong=="54.5733626 -5.9690129")
subset(ni,latlong=="55.0144889 -7.3360632")
subset(ni,latlong=="54.8580155 -6.2781786")
subset(ni,latlong=="54.6643878 -5.6524324")
source('~/fca_fix.R', echo=TRUE)
concentrated
locations
source('~/fca_fix.R', echo=TRUE)
concentrated
locations
subset(ni,latlong=="54.5789384 -5.9637819")
subset(ni,latlong=="54.5807041 -5.969123")
locations
subset(ni,latlong=="54.5126905 -6.0472688")
locations
subset(ni,latlong=="54.5789384 -5.9637819")
subset(ni,latlong=="54.3749008 -6.361876")
a<-read.csv("/Users/francinebennett/Downloads/credit_firms_20140414")
b<-table(a$constituency.name)
mean(b)
notcoded<-read.csv("/Users/francinebennett/Downloads/short_outcodes_not.csv",stringsAsFactors=FALSE)
head(notcoded)
grep("Camberwell",notcoded$Street)
nrow(notcoded)
grep("Camberwell",notcoded$City)
grep("London",notcoded$City)
notcoded[grep("London",notcoded$City),]
nrow(notcoded[grep("London",notcoded$City),])
head(a)
d<-a[grep("Camberwell",a$constituency.name),]
nrow(d)
d
a
c<-a[grep("London and Westminster",a$constituency.name),]
head(c)
source('~/Desktop/client/tsb-embed/frequency_plots.R', echo=TRUE)
head(a)
for (i in 1:length(sensor.list)){
print(i)
name=sensor.list[i]
filename<-paste("/Users/francinebennett/Desktop/client/tsb-embed/presentation/",name,".jpg",sep="")
b<-subset(a,Group.1==name)
b<-b[(nrow(b)-240):nrow(b),]
jpeg(filename)
plot(b$x,type="l",xlab="time (hours)",ylab="value",main=name)
dev.off()
}
a<-read.csv("/Users/francinebennett/Downloads/nhs-dent-stat-eng-2013-14-thir-quar-anx4c-CoT-CCG.csv")
summary(a)
hist(a$Total)
hist(a$Total,c(0,50000))
nrow(a)
dim(a)
head(a)
subset(a,Urgent_Occasional>5000)
subset(a,Urgent_Occasional>8000)
a<-read.csv("/Users/francinebennett/Downloads/dent-earn-expe-eng-wale-2011-12-csv.csv")
a<-read.csv("/Users/francinebennett/Downloads/dent-earn-expe-eng-wale-2011-12-csv.csv")
a<-read.csv("/Users/francinebennett/Downloads/dent-earn-expe-eng-wale-2011-12-csv.csv")
summary(a)
hist(a$Average_Gross_Earnings_.)
hist(a$Average_Gross_Earnings_.,20)
a<-read.csv("/Users/francinebennett/Desktop/incident_phrases.csv")
head(a)
summary(a)
a<-read.csv("/Users/francinebennett/Desktop/incident_phrases.csv",sep="|")
summary(a)
nrow(a)
mene.survey<-read.csv("/Users/francinebennett/Dropbox/datasets/MENE CSV Respondent based data.csv")
head(mene.survey)
hist(mene.survey$q1)
table(mene.survey$PHOFYEAR4)
table(mene.survey$year)
mene.survey<-subset(mene.survey,year=="Y1213") # Filter to most recent data
head(mene.survey)
table(mene.survey$RESIDENCE_LOCALAUTHORITY)
mene.borough<-aggregate(mene.survey$q1,by=list(mene.survey$RESIDENCE_UPPERTIER_LOCALAUTHORITY),FUN=median)
nrow(mene.borough)
head(mene.borough)
mene.borough
table(mene.borough$x)
subset(mene.borough,x==2.5)
subset(mene.survey,RESIDENCE_UPPERTIER_LOCALAUTHORITY=="Flintshire")
mene.borough<-aggregate(mene.survey$q1,by=list(mene.survey$RESIDENCE_UPPERTIER_LOCALAUTHORITY),FUN=median)
head(mene.borough)
mene.survey<-read.csv("/Users/francinebennett/Dropbox/datasets/MENE CSV Respondent based data.csv")
mene.borough<-aggregate(mene.survey$q1,by=list(mene.survey$RESIDENCE_UPPERTIER_LOCALAUTHORITY),FUN=median)
table(mene.survey$RESIDENCE_UPPERTIER_LOCALAUTHORITY)
mene.borough<-aggregate(mene.survey$q1,by=list(mene.survey$RESIDENCE_UPPERTIER_LOCALAUTHORITY),FUN=median)
head(mene.borough)
table(mene.borough$x)
mene.borough<-aggregate(mene.survey$q1,by=list(mene.survey$RESIDENCE_UPPERTIER_LOCALAUTHORITY),FUN=mean)
table(mene.borough$x)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(mene.borough)
head(activity.frequency)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(mene.borough)
ls()
head(borough.healthscore)
borough.healthscore<-merge(borough.healthscore,mene.borough,by.x="LA.code",by.y="Group.1",all=TRUE)
head(borough.healthscore)
borough.healthscore
head(borough.healthscore)
grep("Hartlepool",mene.borough$Group.1)
mene.borough$Group.1[60,]
mene.borough$Group.1[60]
mene.borough[60,]
str(mene.borough)
str(borough.healthscore)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(a)
a
mene.borough[60,]
head(borough.healthscore)
a<-merge(borough.healthscore,mene.borough,by.x="LA.name",by.y="Group.1",all=TRUE)
head(borough.healthscore)
head(a)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(a)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(a)
subset(a,is.na(LA.code))
grep("Birmingham",mene.survey)
head(mene.survey)
head(mene.survey$RESIDENCE_LOCALAUTHORITY)
grep("Birmingham",mene.survey$RESIDENCE_LOCALAUTHORITY)
grep("AMBER",mene.survey)
head(cycling.frequency)
cycling.frequency<-read.xls("/Users/francinebennett/Dropbox/datasets/local-area-walking-and-cycling/cw0111.xls",skip=7)
head(cycling.frequency)
grep("Birmingham",cycling.frequency$Local.Authority)
grep("Birmingham",cycling.frequency$X)
cycling.frequency<-read.xls("/Users/francinebennett/Dropbox/datasets/local-area-walking-and-cycling/cw0111.xls",skip=7)
cycling.frequency<-subset(cycling.frequency,Local.Authority=="")
cycling.frequency$LA.name<-paste(cycling.frequency$X,cycling.frequency$X.1,sep="")
head(cycling.frequency)
nrow(cycling.frequency)
grep("Birmingham",cycling.frequency$LA.name)
cycling.frequency[153,]
cycling.frequency<-read.xls("/Users/francinebennett/Dropbox/datasets/local-area-walking-and-cycling/cw0111.xls",skip=7)
cycling.frequency$LA.name<-paste(cycling.frequency$X,cycling.frequency$X.1,sep="")
cycling.frequency<-subset(cycling.frequency,!is.na("X1.x.per.week") & LA.name!="")
head(cycling.frequency)
cycling.frequency<-cycling.frequency[,c("LA.code","LA.name","X1.x.per.week")] ## Use pct of people who cycle at least once per week
head(cycling.frequency)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(borough.healthscore)
head()
head(a)
head(mene.borough)
head(borough.healthscore)
head(a)
a
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(a)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(a)
a
View(a)
View(a)
View(a)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(a)
view(a)
View(a)
View(a)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(borough.healthscore)
View(borough.healthscore)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(borough.healthscore)
borough.healthscore$greenspace.rank<-rank(borough.healthscore$weekly_greenspace_visits)
head(borough.healthscore)
nrow(borough.healthscore)
?rank
borough.healthscore$greenspace.rank<-rank(borough.healthscore$weekly_greenspace_visits,na.last=NA)
head(mene.borough)
mene.borough<-subset(mene.borough,LA.name!="0")
head(mene.borough)
mene.borough$greenspace.rank<-rank(mene.borough$weekly_greenspace_visits)
head(mene.borough)
source('~/Desktop/client/toothpick/src/toothpick.R', echo=TRUE)
head(borough.healthscore)
